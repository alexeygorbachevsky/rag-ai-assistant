# RAG AI Assistant

A comprehensive AI-powered question-answering system that combines Retrieval-Augmented Generation (RAG) with real-time document processing and intelligent caching mechanisms.

## üé¨ Demo

üöÄ **Live Demo**: [RAG AI Assistant](https://rag-ai-assistant-alexeygorbachevskiys-projects.vercel.app)

üé• **Video Demo**: 

https://github.com/user-attachments/assets/cc624540-e657-4455-b946-34f1ae2a8c4c



## üìã Overview

This application is a full-stack AI assistant that leverages Retrieval-Augmented Generation (RAG) to provide accurate, context-aware responses to user queries. The system integrates document retrieval, semantic search using vector embeddings, and generative AI to deliver intelligent conversational experiences.

## üß± Architecture

### Backend (Node.js/TypeScript)

The backend is built with a modular architecture featuring:

- **Fastify Framework**: High-performance web framework for API endpoints
- **Vector Database Integration**: Semantic search capabilities using vector embeddings
- **LLM Service**: Integration with OpenRouter large language models for text generation
- **Caching System**: Multi-strategy caching (semantic and hash-based) with Redis
- **Rate Limiting**: Comprehensive rate limiting and usage tracking
- **RAG Orchestration**: Intelligent retrieval and generation pipeline

#### Key Components:
- **Controllers**: Handle HTTP requests and responses
- **Services**: Business logic for AI operations, caching, and vector storage
- **Plugins**: Modular functionality for CORS, rate limiting, and AI integration
- **Repositories**: Data access layer for caching and vector operations
- **Middleware**: Request processing, CORS, and rate limiting

### Frontend (Next.js/React)

The frontend provides a modern, responsive user interface with:

- **Real-time Chat Interface**: Interactive conversation with streaming responses
- **Voice Input Support**: Audio recording and transcription capabilities
- **Responsive Design**: Mobile-friendly interface with adaptive layouts
- **State Management**: Context-based state management
- **Component Architecture**: Modular, reusable UI components

#### Key Features:
- **Chat Interface**: Real-time message streaming with typing indicators
- **Audio Visualization**: Visual feedback for voice input
- **Sidebar Navigation**: Collapsible sidebar for additional controls
- **Toast Notifications**: User feedback and error handling
- **Responsive Layout**: Adaptive design for various screen sizes

## üõ†Ô∏è Technology Stack

### Backend
- **Runtime**: Node.js with TypeScript
- **Framework**: Fastify
- **Embeddings**: Hugging Face
- **Database**: Qdrant vector database for embeddings
- **Cache**: Redis for session and response caching
- **AI**: OpenRouter LLM API for text generation
- **Documentation**: Swagger

### Frontend
- **Framework**: Next.js 15 with App Router, React 19
- **Language**: TypeScript
- **Styling**: SCSS modules
- **AI Streaming**: @ai-sdk/react
- **State Management**: React Context API
- **Audio Processing**: Web Speech API
- **UI Components**: Custom component library

## üöÄ Getting Started

### Prerequisites
- Node.js (v18 or higher)
- Yarn package manager
- Redis server
- Qdrant database instance

### Installation

1. Clone the repository
2. Install backend dependencies:
   ```bash
   cd backend
   yarn install
   ```

3. Install frontend dependencies:
   ```bash
   cd frontend
   yarn install
   ```

4. Configure environment variables:
   - Copy `backend/env.example` to `backend/.env`
   - Edit `.env` file with your API keys and configuration
5. Start the development servers

### Development

- Frontend: `yarn dev` (runs on port 3000)
- Backend: `yarn dev` (runs on port 3001)

## üê≥ Deployment

The application includes Docker support for containerized deployment.

## üìÑ License

MIT License - see [LICENSE](LICENSE) file for details. 
